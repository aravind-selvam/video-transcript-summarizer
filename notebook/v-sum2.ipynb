{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Summarizer Using Bart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code defines two functions, `write_srt` and `format_timestamp`. \n",
    "- The `write_srt` function takes in an iterator of dictionaries (representing transcript segments) and a file object and writes the transcript data to the file in SubRip (.srt) format. \n",
    "- The `format_timestamp` function converts a timestamp in seconds to a string in the format \"HH:MM:SS,mmm\" (hours, minutes, seconds, and milliseconds) and is used by the write_srt function to format the start and end timestamps of each transcript segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from typing import Iterator, TextIO\n",
    "\n",
    "def write_srt(transcript: Iterator[dict], file: TextIO):\n",
    "    for i, segment in enumerate(transcript, start=1):\n",
    "        print(\n",
    "            f\"{i}\\n\"\n",
    "            f\"{format_timestamp(segment['start'], always_include_hours=True)} --> \"\n",
    "            f\"{format_timestamp(segment['end'], always_include_hours=True)}\\n\"\n",
    "            f\"{segment['text'].strip().replace('-->', '->')}\\n\",\n",
    "            file=file,\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "def format_timestamp(seconds: float, always_include_hours: bool = False):\n",
    "    assert seconds >= 0, \"non-negative timestamp expected\"\n",
    "    timestamp = timedelta(seconds=seconds)\n",
    "    total_seconds = int(timestamp.total_seconds())\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    hours_marker = f\"{hours}:\" if always_include_hours or hours > 0 else \"\"\n",
    "    return f\"{hours_marker}{minutes:02d}:{seconds:02d}.{timestamp.microseconds // 1000:03d}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using video path, a model path, and a task (either \"stt\" or \"asr\") and generate subtitle for the video\n",
    "\n",
    "- The code defines a function `\"get_audio\"` that takes a list of file paths and extracts the audio from them using FFmpeg library, it stores the audio in .wav format in a temp directory and returns a dictionary of the original file path as key and the audio file path as value.\n",
    "- The function `\"generate_subtitles\"` takes in an audio file path, an srt file path, and a transcribe function, it transcribes the audio, generates subtitles and writes the subtitles in srt format at the provided file path.\n",
    "- The function `\"get_subtitles\"` takes a list of file paths, a flag to indicate if the subtitles should be written to a provided directory or a temp directory, an output directory path, and a transcribe function, it calls the get_audio function to extract audio from the provided file paths, calls the generate_subtitles function to generate subtitles for each audio file, and returns a dictionary of file path as key and srt file path as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\iNeuron\\Project_Neuron\\video_summarizer\\vsum\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import warnings\n",
    "import tempfile\n",
    "import ffmpeg\n",
    "\n",
    "def get_audio(paths):\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    audio_paths = {}\n",
    "    for path in paths:\n",
    "        filename = os.path.basename(path).split('.')[0]\n",
    "        print(f\"Extracting audio from {os.path.basename(path)}...\")\n",
    "        output_path = os.path.join(temp_dir, f\"{filename}.wav\")\n",
    "\n",
    "        ffmpeg.input(path).output(\n",
    "            output_path,\n",
    "            acodec=\"pcm_s16le\", ac=1, ar=\"16k\"\n",
    "        ).run(quiet=True, overwrite_output=True)\n",
    "        audio_paths[path] = output_path\n",
    "    return audio_paths\n",
    "\n",
    "def generate_subtitles(audio_path, srt_path, transcribe):\n",
    "    print(f\"Generating subtitles for {os.path.basename(audio_path)}... This might take a while.\")\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    result = transcribe(audio_path)\n",
    "    warnings.filterwarnings(\"default\")\n",
    "\n",
    "    with open(srt_path, \"w\", encoding=\"utf-8\") as srt:\n",
    "        write_srt(result[\"segments\"], file=srt)\n",
    "    return result\n",
    "\n",
    "def get_subtitles(audio_paths: list, output_srt: bool, output_dir: str, transcribe: callable):\n",
    "    srt_path = output_dir if output_srt else tempfile.gettempdir()\n",
    "    subtitles_path = {}\n",
    "\n",
    "    for path, audio_path in audio_paths.items():\n",
    "        filename = os.path.basename(path).split('.')[0]\n",
    "        srt_path = os.path.join(srt_path, f\"{filename}.srt\")\n",
    "\n",
    "        result = generate_subtitles(audio_path, srt_path, transcribe)\n",
    "\n",
    "        subtitles_path[path] = srt_path\n",
    "    \n",
    "    return subtitles_path , result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the subtite functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_subtitle(video_path:str, model:str, output_dir:str, srt:bool, verbose:bool, \n",
    "                ):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if model.endswith(\".en\"):\n",
    "        print(f\"{model} is a English model\")\n",
    "    model = whisper.load_model(model)\n",
    "    audio = get_audio(video_path)\n",
    "    subtitle = get_subtitles(\n",
    "                audio, srt, output_dir, lambda audio_path: model.transcribe(audio_path, \n",
    "                                                verbose=verbose, task='transcribe'))\n",
    "    return subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny.en is a English model\n",
      "Extracting audio from 003_Project Setup.mp4...\n",
      "Generating subtitles for 003_Project Setup.wav... This might take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18421/18421 [00:19<00:00, 965.58frames/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "vid_path = r\"D:\\Recordings\\final\\pyproject\\003_Project Setup.mp4\"\n",
    "try:\n",
    "    subtitle = auto_subtitle(video_path=[vid_path],\n",
    "    model='tiny.en', output_dir='srt', srt=True, verbose=False)\n",
    "except Exception as e:\n",
    "    print(f'error {sys.stderr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitle['D:\\\\iNeuron\\\\Project_Neuron\\\\Video summarization\\\\vid\\\\sample.mp4'] = 'srt\\\\sample_mp4.srt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for adding subtitle to video as overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001_Introduction\n",
      "Adding subtitles to 001_Introduction...\n",
      "Saved subtitled video to D:\\iNeuron\\Project_Neuron\\Video summarization\\001_Introduction.mp4.\n"
     ]
    }
   ],
   "source": [
    "def add_subtitles(path: str, subtitles_path: str, output_dir: str):\n",
    "    try:\n",
    "      filename = os.path.basename(path).split('.')[0]\n",
    "      print(filename)\n",
    "      out_path = os.path.join(output_dir, f\"{filename}.mp4\")\n",
    "\n",
    "      print(f\"Adding subtitles to {filename}...\")\n",
    "\n",
    "      video = ffmpeg.input(path)\n",
    "      audio = video.audio\n",
    "\n",
    "      stderr = ffmpeg.concat(\n",
    "        video.filter('subtitles', subtitles_path, force_style=\"OutlineColour=&H40000000,BorderStyle=3\"), audio, v=1, a=1\n",
    "      ).output(out_path).run(quiet=True, overwrite_output=True)\n",
    "\n",
    "      print(f\"Saved subtitled video to {os.path.abspath(out_path)}.\")\n",
    "    except Exception as e:\n",
    "        print(e, sys.stderr)\n",
    "\n",
    "def main(subtitles: dict, output_dir: str):\n",
    "    try:\n",
    "      for path, srt_path in subtitles.items():\n",
    "         add_subtitles(path, srt_path, output_dir)\n",
    "    except Exception as e:\n",
    "        print(e, sys.stderr)\n",
    "\n",
    "main(subtitle[0], r'D:\\iNeuron\\Project_Neuron\\Video summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.basename('D:\\\\iNeuron\\\\Project_Neuron\\\\Video summarization\\\\vid\\\\sample.mp4').split('.')[0]\n",
    "print(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM,AutoTokenizer\n",
    "\n",
    "# Load tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "# Load model \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" In this video, we will be creating our basic project setup . Let's start with GitHub, then click on Repostries and create a private repository . Next step is we will just clone this report to our local system . We can make whatever changes we want in this local repo and then push it after every change .\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(subtitle[1]['text'], \n",
    "                max_length=512, \n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\")\n",
    "\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], max_new_tokens=512)\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "327958b19781b0c869d788a5162e84c090433f2765a7e362f8a73cb835d6aa0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
